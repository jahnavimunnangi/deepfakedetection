# Deepfake Detection & Localization using Spatialâ€“Frequency Features

This project detects **manipulated (deepfake) images** and highlights the **exact regions** that are likely to be fake using a dual-stream deep learning model and Grad-CAM visualization.

## ðŸŽ¯ Objective

- Classify an input image as **REAL** or **FAKE**
- Localize manipulated regions using a **heatmap overlay**
- Provide an easy-to-use **Streamlit web app** for demo

## ðŸ§  Model Overview

The system uses a **dual-stream deep learning model**:

1. **Spatial Stream**
   - Takes the RGB image as input
   - Learns texture and visual artifacts in the spatial domain
   - Uses a CNN backbone (e.g., Xception / ResNet)

2. **Frequency Stream**
   - Converts image to frequency domain (using `FrequencyTransformer`)
   - Learns artifacts in magnitude & phase components
   - Helps detect subtle manipulations not visible in raw pixels

The outputs of both streams are fused and passed through a classifier to predict:
- `1` â†’ FAKE  
- `0` â†’ REAL  

For localization, **Grad-CAM** is applied on the spatial stream to generate a heatmap of suspicious regions.

## ðŸ“¦ Tech Stack

- Python
- PyTorch
- Streamlit
- NumPy, OpenCV, PIL
- Matplotlib

## ðŸ“‚ Main Files

- `streamlit_app.py` â€“ Streamlit UI for uploading an image and viewing results  
- `deepfake_localization.py` â€“ DeepfakeLocalizer class + Grad-CAM visualization  
- `total_code.py` â€“ Model architecture and preprocessing config  
- `training_code.ipynb` â€“ Model training notebook  
- `requirements.txt` â€“ List of dependencies  

## ðŸš€ How to Run (Locally)

1. Create and activate a virtual environment (optional but recommended)

```bash
python -m venv venv
venv\Scripts\activate   # On Windows
# or
source venv/bin/activate  # On Linux/Mac
